<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Abhishek Sharma on Abhishek Sharma</title>
    <link>/</link>
    <description>Recent content in Abhishek Sharma on Abhishek Sharma</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Thu, 27 Sep 2018 00:00:00 +0800</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>sarathi</title>
      <link>/opensource/sarathi/</link>
      <pubDate>Tue, 07 May 2024 00:00:00 +0800</pubDate>
      
      <guid>/opensource/sarathi/</guid>
      <description>&lt;p&gt;Sarathi is an  LLM-based, simple command line interface-based coding assistant. ThIt ca write detailed commit messages and documentation for a python codebases &lt;a href=&#34;https://github.com/abhishek9sharma/sarathi&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Automated Identification of Libraries from Vulnerability Data:Can We Do Better?</title>
      <link>/publication/xmtc/</link>
      <pubDate>Sat, 19 Mar 2022 00:00:00 +0800</pubDate>
      
      <guid>/publication/xmtc/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Analyzing Offline Social Engagements: AnEmpirical Study of Meetup Events Related to Software Development</title>
      <link>/publication/meetup/</link>
      <pubDate>Fri, 14 Jan 2022 01:00:00 +0800</pubDate>
      
      <guid>/publication/meetup/</guid>
      <description></description>
    </item>
    
    <item>
      <title>HERMES: Using Commit-Issue Linking to Detect Vulnerability-Fixing Commits</title>
      <link>/publication/vcur2/</link>
      <pubDate>Fri, 14 Jan 2022 00:00:00 +0800</pubDate>
      
      <guid>/publication/vcur2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>mlopsdemo</title>
      <link>/opensource/mlops/</link>
      <pubDate>Tue, 07 Dec 2021 00:00:00 +0800</pubDate>
      
      <guid>/opensource/mlops/</guid>
      <description>&lt;p&gt;A mini Dockerized ML system with MLOPS capabilities (train/deploy). It can train/deploy models for recommendation/classification given user+stores click interaction data set and automatically deploy models to be served by a simple python web API end point. You can find the source code of the application &lt;a href=&#34;https://github.com/abhishek9sharma/mlopsdemo&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Post2Vec: Learning Distributed Representations of Stack Overflow Posts</title>
      <link>/publication/post2vec/</link>
      <pubDate>Tue, 06 Jul 2021 00:00:00 +0800</pubDate>
      
      <guid>/publication/post2vec/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Out of sight, out of mind? How vulnerable dependencies affect open-source projects</title>
      <link>/publication/outofsight/</link>
      <pubDate>Wed, 21 Apr 2021 00:00:00 +0800</pubDate>
      
      <guid>/publication/outofsight/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Machine Learning Approach for Vulnerability Curation</title>
      <link>/publication/vulncur/</link>
      <pubDate>Fri, 26 Jun 2020 00:00:00 +0800</pubDate>
      
      <guid>/publication/vulncur/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SIEVE: Helping Developers Sift Wheat from Chaff via Cross-Platform Analysis</title>
      <link>/publication/sieve/</link>
      <pubDate>Fri, 27 Sep 2019 00:00:00 +0800</pubDate>
      
      <guid>/publication/sieve/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Recommending Who to Follow in the Software Engineering Twitter Space</title>
      <link>/publication/software-experts/</link>
      <pubDate>Thu, 27 Sep 2018 00:00:00 +0800</pubDate>
      
      <guid>/publication/software-experts/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Part 1: Introduction to Guardrails-AI Python Library</title>
      <link>/tutorial/guardrails-ai/guardrail_intro/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 +0800</pubDate>
      
      <guid>/tutorial/guardrails-ai/guardrail_intro/</guid>
      <description>

&lt;h1 id=&#34;1-set-up-environment&#34;&gt;1. Set up environment&lt;/h1&gt;

&lt;h2 id=&#34;1-1-install-a-virtual-env-with-all-dependencies&#34;&gt;1.1 Install a Virtual env with all dependencies&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  %%bash
  uv venv guarded_llm_env
  source guarded_llm_env/bin/activate
  uv pip install ipykernel guardrails-ai nbconvert
  python -m ipykernel install --user --name=guarded_llm_env

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;1-2-activate-the-kernel&#34;&gt;1.2 Activate the Kernel&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;refresh the browser&lt;/li&gt;
&lt;li&gt;activate the &lt;strong&gt;guarded_llm_env&lt;/strong&gt; kernel&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;2-normal-llm-calls&#34;&gt;2. Normal LLM Calls&lt;/h1&gt;

&lt;h2 id=&#34;2-1-set-up-your-llm-provider-and-authentication-token&#34;&gt;2.1 Set up your LLM Provider and Authentication token&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;  # import os
  # os.environ[&amp;quot;LLM_API_TOKEN&amp;quot;] = &amp;quot;sk-123&amp;quot;

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;  LLM_PROVIDER_BASE=&amp;quot;https://api.openai.com/v1&amp;quot;
  LLM_API_TOKEN=os.environ[&amp;quot;LLM_API_TOKEN&amp;quot;] 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;  user_chat_request = {
      &amp;quot;messages&amp;quot;:[
          {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, 
            &amp;quot;content&amp;quot;: &amp;quot;Are python developers dumb idiotic and should they use rust&amp;quot;}
      ],
      &amp;quot;stream&amp;quot;:True,
      &amp;quot;max_tokens&amp;quot;:50,
      &amp;quot;model&amp;quot;: &amp;quot;gpt-3.5-turbo&amp;quot;
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;2-2-make-an-normal-llm-call&#34;&gt;2.2 Make an normal LLM Call&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;I am using litellm completion method here&lt;/li&gt;
&lt;li&gt;Reference : &lt;a href=&#34;https://docs.litellm.ai/docs/completion/input&#34; target=&#34;_blank&#34;&gt;https://docs.litellm.ai/docs/completion/input&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;  import litellm
  from typing import Dict, Any

  def call_llm(provider_base, provider_key, *args, **kwargs) -&amp;gt; str:
      &amp;quot;&amp;quot;&amp;quot;Calls an LLM using litellm.completion.&amp;quot;&amp;quot;&amp;quot;

      #some bug in litellm version
      if &amp;quot;msg_history&amp;quot; in kwargs:
          kwargs.pop(&amp;quot;msg_history&amp;quot;)
          
      response = litellm.completion(
          api_base=provider_base,
          api_key=provider_key,
          **kwargs
      )
      if &amp;quot;stream&amp;quot; in kwargs and kwargs[&amp;quot;stream&amp;quot;]:
          for resp in response:
              if resp.choices[0].delta.content:  # Some responses may not have content
                  chunk = resp.choices[0].delta.content
                  #print(chunk, end=&amp;quot;&amp;quot;, flush=True)  # Print in real-time
                  yield chunk
      else:
          yield response[&#39;choices&#39;][0][&#39;message&#39;][&#39;content&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;  for chunk_resp in call_llm(provider_base=LLM_PROVIDER_BASE, provider_key=LLM_API_TOKEN, **user_chat_request):
      print(chunk_resp, end=&amp;quot;&amp;quot;, flush=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;3-guarded-llm-calls&#34;&gt;3. Guarded LLM Calls&lt;/h1&gt;

&lt;h2 id=&#34;3-1-install-guard-from-guardrails-hub&#34;&gt;3.1 Install Guard from Guardrails HUB&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Go to &lt;a href=&#34;https://hub.guardrailsai.com/&#34; target=&#34;_blank&#34;&gt;https://hub.guardrailsai.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Get Your token and configure it locally&lt;/li&gt;
&lt;li&gt;Install your required guard&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;### 3.1.1 Configure Hub Token&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;  # import os
  # os.environ[&amp;quot;GR_TOKEN&amp;quot;]=&amp;quot;GRTOKENHERE&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  %%bash
  source guarded_llm_env/bin/activate
  guardrails configure --disable-remote-inferencing --disable-metrics --token $GR_TOKEN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;### 3.1.2 Install Guardrail From Hub&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  %%bash
  source guarded_llm_env/bin/activate &amp;amp;&amp;amp; guardrails hub install hub://guardrails/profanity_free
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;3-2-call-llm-with-guardrails&#34;&gt;3.2 Call LLM with Guardrails&lt;/h2&gt;

&lt;p&gt;### 3.2.1 Initialize Guardrail Object&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;  import guardrails as gd
  from guardrails.hub import ProfanityFree
  from guardrails import OnFailAction
  profanity_guard =  gd.Guard(name=&amp;quot;Profanity&amp;quot;).use(ProfanityFree, on_fail=OnFailAction.EXCEPTION)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;### 3.2.2 Apply GuardRails on Inputs&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;  def call_llm_guard_input(provider_base, provider_key, chat_request: Dict[str, Any], guard_to_apply=None) -&amp;gt; str:
      &amp;quot;&amp;quot;&amp;quot;Calls an LLM with Profanity Guard&amp;quot;&amp;quot;&amp;quot;
      if guard_to_apply:
          #Validate Input Only
          try:
              for msg in chat_request[&amp;quot;messages&amp;quot;]:
                  guard_to_apply.validate(msg[&amp;quot;content&amp;quot;])
          except Exception as e:
              error_str = &amp;quot;INPUT_GUARD_FAILED::&amp;quot; + str(e)
              yield error_str

              
      else:
          for chunk_resp in call_llm(provider_base=LLM_PROVIDER_BASE, provider_key=LLM_API_TOKEN, **user_chat_request):
              yield chunk_resp
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;  #Call with Input Guards
  for chunk_resp in call_llm_guard_input(provider_base=LLM_PROVIDER_BASE, 
                                        provider_key=LLM_API_TOKEN, 
                                        chat_request=user_chat_request, 
                                        guard_to_apply=profanity_guard):
      print(chunk_resp, end=&amp;quot;&amp;quot;, flush=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;### 3.2.3 Apply GuardRails on Inputs plus Outputs&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;  def call_llm_guard_output(provider_base, provider_key, chat_request: Dict[str, Any], guard_to_apply=None) -&amp;gt; str:
      &amp;quot;&amp;quot;&amp;quot;Calls an LLM with Profanity Guard&amp;quot;&amp;quot;&amp;quot;
      if guard_to_apply:
          
          try:
              llm_output_gen =profanity_guard(call_llm,provider_base=LLM_PROVIDER_BASE, provider_key=LLM_API_TOKEN, **chat_request)
              for validation_outcome in llm_output_gen:
                  if validation_outcome.validation_passed==True:
                      yield validation_outcome.validated_output
          except Exception as e:
              error_str = &amp;quot;OUTPUT_GUARD_FAILED::&amp;quot; + str(e)
              yield error_str        
              
      else:
          for chunk_resp in call_llm(provider_base=LLM_PROVIDER_BASE, provider_key=LLM_API_TOKEN, **user_chat_request):
              yield chunk_resp

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;  #Call LLM with OUTPUT  Guards
  for chunk_resp in call_llm_guard_output(provider_base=LLM_PROVIDER_BASE, provider_key=LLM_API_TOKEN, chat_request=user_chat_request, guard_to_apply=profanity_guard):
      print(chunk_resp, end=&amp;quot;&amp;quot;, flush=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;  def call_llm_guarded(provider_base, provider_key, chat_request: Dict[str, Any], guard_to_apply=None) -&amp;gt; str:
      &amp;quot;&amp;quot;&amp;quot;Calls an LLM with Profanity Guard&amp;quot;&amp;quot;&amp;quot;
      if guard_to_apply:

          #Validate Input Only
          try:
              for msg in chat_request[&amp;quot;messages&amp;quot;]:
                  guard_to_apply.validate(msg[&amp;quot;content&amp;quot;])
          except Exception as e:
              error_str = &amp;quot;INPUT_GUARD_FAILED::&amp;quot; + str(e)
              yield error_str

          try:
              llm_output_gen =profanity_guard(call_llm,provider_base=LLM_PROVIDER_BASE, provider_key=LLM_API_TOKEN, **chat_request)
              for validation_outcome in llm_output_gen:
                  if validation_outcome.validation_passed==True:
                      yield validation_outcome.validated_output
          except Exception as e:
              error_str = &amp;quot;OUTPUT_GUARD_FAILED::&amp;quot; + str(e)
              yield error_str        
              
              
      else:
          for chunk_resp in call_llm(provider_base=LLM_PROVIDER_BASE, provider_key=LLM_API_TOKEN, **user_chat_request):
              yield chunk_resp

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;  user_chat_request_new = {
      &amp;quot;messages&amp;quot;:[
          {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, 
            &amp;quot;content&amp;quot;: &amp;quot;Complete the below sentence. he is in id**t &amp;quot;}
      ],
      &amp;quot;stream&amp;quot;:True,
      &amp;quot;max_tokens&amp;quot;:50,
      &amp;quot;model&amp;quot;: &amp;quot;gpt-3.5-turbo&amp;quot;
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;  #Call LLM with OUTPUT  Guards
  for chunk_resp in call_llm_guarded(provider_base=LLM_PROVIDER_BASE, 
                                          provider_key=LLM_API_TOKEN, 
                                          chat_request=user_chat_request_new,
                                          guard_to_apply=profanity_guard):
      print(chunk_resp, end=&amp;quot;&amp;quot;, flush=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Part 2: Deploying a Guarded Endpoint Using FastAPI</title>
      <link>/tutorial/guardrails-ai/guardrail_serve/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 +0800</pubDate>
      
      <guid>/tutorial/guardrails-ai/guardrail_serve/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Part 3: Adding a Custom Validator to Guardrails-AI</title>
      <link>/tutorial/guardrails-ai/guardrail_validator/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 +0800</pubDate>
      
      <guid>/tutorial/guardrails-ai/guardrail_validator/</guid>
      <description></description>
    </item>
    
    <item>
      <title>APIBot: Question Answering Bot for API documentation</title>
      <link>/publication/apibot/</link>
      <pubDate>Sat, 11 Nov 2017 00:00:00 +0800</pubDate>
      
      <guid>/publication/apibot/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Personality and Project Success: Insights from a Large-Scale Study with Professionals</title>
      <link>/publication/personality/</link>
      <pubDate>Sun, 17 Sep 2017 00:00:00 +0800</pubDate>
      
      <guid>/publication/personality/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
